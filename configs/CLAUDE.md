# æ¨¡å—å¯¼èˆªï¼šconfigs/

> [æ ¹ç›®å½• CLAUDE.md](../CLAUDE.md)

---

## ğŸ“¦ ç›®å½•æ¦‚è¿°

`configs/` ç›®å½•ä½¿ç”¨ **Hydra** é…ç½®ç®¡ç†ç³»ç»Ÿç®¡ç†é¡¹ç›®ä¸­çš„æ‰€æœ‰é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒæ¨¡å—åŒ–ã€å¯ç»„åˆçš„é…ç½®æ–¹æ¡ˆã€‚

**é…ç½®æ ¼å¼**ï¼šYAML + JSON
**ç®¡ç†æ¡†æ¶**ï¼šHydra + OmegaConf
**ç‰¹æ€§**ï¼š
- åŠ¨æ€é…ç½®åŠ è½½
- é…ç½®ç»„åˆä¸ç»§æ‰¿
- å‚æ•°è¦†ç›–
- å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
- å¤šç¯å¢ƒé…ç½®

---

## ğŸ—‚ï¸ é…ç½®æ–‡ä»¶ç»“æ„

```
configs/
â”œâ”€â”€ config.json              # å…¨å±€é…ç½®
â”œâ”€â”€ hifigan.yml              # HiFi-GAN å£°ç å™¨é…ç½®
â”œâ”€â”€ v2/
â”‚   â””â”€â”€ vc_wrapper.yaml      # V2ç‰ˆæœ¬æ¨¡å‹åŒ…è£…å™¨é…ç½®
â”œâ”€â”€ astral_quantization/
â”‚   â”œâ”€â”€ default_2048.yml     # 2048ç»´é‡åŒ–é…ç½®
â”‚   â”œâ”€â”€ default_32.yml       # 32ç»´é‡åŒ–é…ç½®
â”‚   â””â”€â”€ config.json          # é‡åŒ–æ¨¡å—é…ç½®
â””â”€â”€ presets/
    â”œâ”€â”€ config_dit_mel_seed_uvit_whisper_base_f0_44k.yml
    â”œâ”€â”€ config_dit_mel_seed_uvit_whisper_small_wavenet.yml
    â””â”€â”€ config_dit_mel_seed_uvit_xlsr_tiny.yml
```

---

## ğŸ“„ æ ¸å¿ƒé…ç½®æ–‡ä»¶

### 1. [config.json](config.json) - å…¨å±€é…ç½®

**åŠŸèƒ½**ï¼šå®šä¹‰é¡¹ç›®çš„å…¨å±€å‚æ•°å’Œé»˜è®¤è®¾ç½®

**ä¸»è¦å†…å®¹**ï¼š
```json
{
  "model": {
    "name": "seed_vc",
    "version": "v1",
    "sample_rate": 24000,
    "hop_length": 256,
    "win_length": 1024
  },
  "training": {
    "batch_size": 32,
    "learning_rate": 0.0001,
    "epochs": 100,
    "save_interval": 10,
    "eval_interval": 5
  },
  "inference": {
    "diffusion_steps": 10,
    "length_adjust": 1.0,
    "inference_cfg_rate": 0.7,
    "f0_condition": false,
    "auto_f0_adjust": true
  },
  "device": {
    "use_cuda": true,
    "cuda_device": 0,
    "use_mps": false
  }
}
```

**å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| model.sample_rate | int | 24000 | é‡‡æ ·ç‡ |
| model.hop_length | int | 256 | è·³è·ƒé•¿åº¦ |
| model.win_length | int | 1024 | çª—å£é•¿åº¦ |
| training.batch_size | int | 32 | æ‰¹å¤„ç†å¤§å° |
| training.learning_rate | float | 0.0001 | å­¦ä¹ ç‡ |
| inference.diffusion_steps | int | 10 | æ‰©æ•£æ­¥æ•° |
| inference.length_adjust | float | 1.0 | é•¿åº¦è°ƒèŠ‚ç³»æ•° |
| inference.inference_cfg_rate | float | 0.7 | æ¨ç†CFGç‡ |

---

### 2. [hifigan.yml](hifigan.yml) - HiFi-GAN é…ç½®

**åŠŸèƒ½**ï¼šé…ç½® HiFi-GAN å£°ç å™¨çš„å‚æ•°

**ä¸»è¦å†…å®¹**ï¼š
```yaml
model:
  in_channels: 80  # è¾“å…¥é€šé“æ•° (æ¢…å°”é¢‘è°±ç»´åº¦)
  resblock: 1     # æ®‹å·®å—ç±»å‹
  num_gpus: 1     # GPU æ•°é‡
  batch_size: 32  # æ‰¹å¤„ç†å¤§å°

audio:
  sr: 24000       # é‡‡æ ·ç‡
  hop_length: 256 # è·³è·ƒé•¿åº¦
  win_length: 1024 # çª—å£é•¿åº¦
```

---

### 3. [v2/vc_wrapper.yaml](v2/vc_wrapper.yaml) - V2æ¨¡å‹é…ç½®

**åŠŸèƒ½**ï¼šé…ç½® V2ç‰ˆæœ¬çš„è¯­éŸ³è½¬æ¢æ¨¡å‹åŒ…è£…å™¨

**ä¸»è¦å†…å®¹**ï¼š
```yaml
defaults:
  - encodec: encodec_24k
  - diffusion: dit_mel_seed_uvit_base
  - decoder: bigvgan_24k_100h

_encodec:
  _target_: modules.encodec.EnCodec
  sample_rate: 24000
  bandwidths: [3.0, 6.0, 12.0]

_diffusion:
  _target_: modules.diffusion_transformer.DiffusionTransformer
  hidden_size: 768
  num_heads: 12
  num_layers: 24
  condition_dim: 256

_decoder:
  _target_: modules.bigvgan.BigVGAN
  sample_rate: 24000
  upsample_rates: [5, 4, 3, 2]
  Gin_channels: 256
  use_cuda_graph: false
```

**ç»„ä»¶è¯´æ˜**ï¼š

| ç»„ä»¶ | ç±»å | å‚æ•° | è¯´æ˜ |
|------|------|------|------|
| ç¼–ç å™¨ | EnCodec | sample_rate, bandwidths | éŸ³é¢‘ç¼–ç  |
| æ‰©æ•£æ¨¡å‹ | DiffusionTransformer | hidden_size, num_heads, num_layers | æ¡ä»¶ç”Ÿæˆ |
| è§£ç å™¨ | BigVGAN | sample_rate, upsample_rates | æ³¢å½¢åˆæˆ |

---

## ğŸ¯ é¢„è®¾é…ç½®

### é¢„ç½®æ¨¡å‹é…ç½®

| é…ç½®æ–‡ä»¶ | æ¨¡å‹ç±»å‹ | å‚æ•°é‡ | æ¨ç†é€Ÿåº¦ | è´¨é‡ |
|----------|----------|--------|----------|------|
| `config_dit_mel_seed_uvit_whisper_base_f0_44k.yml` | Base | ~150M | ä¸­ç­‰ | é«˜ |
| `config_dit_mel_seed_uvit_whisper_small_wavenet.yml` | Small | ~80M | å¿« | ä¸­ |
| `config_dit_mel_seed_uvit_xlsr_tiny.yml` | Tiny | ~40M | å¾ˆå¿« | ä½ |

---

### Base é…ç½®è¯¦æƒ…

**æ–‡ä»¶å**ï¼š`presets/config_dit_mel_seed_uvit_whisper_base_f0_44k.yml`

```yaml
defaults:
  - _self_

model:
  name: "dit_mel_seed_uvit_base"
  version: "v2"
  sample_rate: 44100
  num_mels: 80
  hop_length: 256
  win_length: 1024

  transformer:
    hidden_size: 768
    num_heads: 12
    num_layers: 24
    dropout: 0.1
    layer_norm_epsilon: 1e-6

  f0:
    extractor: "rmvpe"
    condition: true
    auto_adjust: true

  diffusion:
    num_steps: 25
    beta_schedule: "cosine"
    beta_start: 0.0001
    beta_end: 0.02

  decoder:
    type: "wavenet"
    residual_channels: 512
    dilation_rates: [1, 3, 9]
    num_res_blocks: 4

training:
  batch_size: 16
  gradient_accumulation_steps: 4
  learning_rate: 0.0001
  warmup_steps: 1000
  max_epochs: 100
  save_interval: 10
  eval_interval: 5
  log_interval: 100

inference:
  diffusion_steps: 25
  length_adjust: 1.0
  inference_cfg_rate: 0.7
  f0_condition: true
  auto_f0_adjust: true
  pitch_shift: 0
  stream_output: true
```

---

### Small é…ç½®è¯¦æƒ…

**æ–‡ä»¶å**ï¼š`presets/config_dit_mel_seed_uvit_whisper_small_wavenet.yml`

```yaml
model:
  name: "dit_mel_seed_uvit_small"
  sample_rate: 24000
  num_mels: 80

  transformer:
    hidden_size: 512
    num_heads: 8
    num_layers: 12
    dropout: 0.1

  diffusion:
    num_steps: 10
    beta_schedule: "linear"

  decoder:
    type: "wavenet_small"
    residual_channels: 256
    dilation_rates: [1, 3, 9]
    num_res_blocks: 3

training:
  batch_size: 32
  learning_rate: 0.0002
  max_epochs: 80
```

---

### Tiny é…ç½®è¯¦æƒ…

**æ–‡ä»¶å**ï¼š`presets/config_dit_mel_seed_uvit_xlsr_tiny.yml`

```yaml
model:
  name: "dit_mel_seed_uvit_tiny"
  sample_rate: 16000
  num_mels: 64

  transformer:
    hidden_size: 256
    num_heads: 4
    num_layers: 6
    dropout: 0.1

  diffusion:
    num_steps: 5
    beta_schedule: "linear"

  decoder:
    type: "wavenet_tiny"
    residual_channels: 128
    num_res_blocks: 2

training:
  batch_size: 64
  learning_rate: 0.0003
  max_epochs: 60
```

---

## ğŸ”§ é‡åŒ–é…ç½®

### [astral_quantization/default_2048.yml](astral_quantization/default_2048.yml)

**åŠŸèƒ½**ï¼š2048ç»´ Astral é‡åŒ–é…ç½®

```yaml
quantizer:
  codebook_size: 2048
  commitment_cost: 0.25
  decay: 0.99
  eps: 1e-5

  resolution: 2048
  masking_ratio: 0.0
  l2_norm: false

performance:
  num_bits: 11
  compression_ratio: 10.9
  reconstruction_quality: "high"
```

### [astral_quantization/default_32.yml](astral_quantization/default_32.yml)

**åŠŸèƒ½**ï¼š32ç»´è½»é‡é‡åŒ–é…ç½®

```yaml
quantizer:
  codebook_size: 32
  commitment_cost: 0.25
  decay: 0.99
  eps: 1e-5

  resolution: 32
  masking_ratio: 0.1
  l2_norm: true

performance:
  num_bits: 5
  compression_ratio: 96.0
  reconstruction_quality: "medium"
```

---

## ğŸ› ï¸ é…ç½®ä½¿ç”¨æŒ‡å—

### 1. åŠ è½½é…ç½®

```python
import yaml
from hydra import compose, initialize_config_dir
from hydra.utils import instantiate
from omegaconf import DictConfig

# æ–¹æ³•1ï¼šç›´æ¥åŠ è½½ YAML
with open("configs/v2/vc_wrapper.yaml", "r") as f:
    config = yaml.safe_load(f)

# æ–¹æ³•2ï¼šä½¿ç”¨ Hydra (æ¨è)
from hydra import initialize_config_dir, instantiate

with initialize_config_dir(config_dir="configs"):
    cfg = compose(config_name="v2/vc_wrapper.yaml")
    model = instantiate(cfg.model)

# æ–¹æ³•3ï¼šéƒ¨åˆ†åŠ è½½
with open("configs/config.json", "r") as f:
    global_config = json.load(f)

with open("configs/v2/vc_wrapper.yaml", "r") as f:
    model_config = yaml.safe_load(f)

combined_config = {**global_config, **model_config}
```

### 2. å‘½ä»¤è¡Œè¦†ç›–å‚æ•°

```bash
# è¿è¡Œæ—¶è¦†ç›–é…ç½®
python inference_v2.py \\
    --config-path=configs/v2 \\
    --config-name=vc_wrapper \\
    diffusion.num_steps=25 \\
    diffusion.beta_schedule=cosine \\
    decoder.use_cuda_graph=true \\
    inference.f0_condition=true
```

### 3. å¤šé…ç½®æ–‡ä»¶åˆå¹¶

```python
# Hydra defaults æœºåˆ¶
defaults:
  - encodec: encodec_24k
  - diffusion: dit_mel_seed_uvit_base
  - decoder: bigvgan_24k_100h
  - _self_

# è¿è¡Œæ—¶æ·»åŠ æ›´å¤šé»˜è®¤é…ç½®
python script.py --config-path=configs \\
    --config-name=v2/vc_wrapper \\
    +encodec=encodec_48k \\
    +diffusion=dit_mel_seed_uvit_large
```

### 4. é…ç½®éªŒè¯

```python
from pydantic import BaseModel, ValidationError

class ModelConfig(BaseModel):
    hidden_size: int
    num_heads: int
    num_layers: int

# éªŒè¯é…ç½®
def validate_config(config_dict):
    try:
        config = ModelConfig(**config_dict)
        return True, config
    except ValidationError as e:
        return False, str(e)
```

---

## ğŸ”„ é…ç½®ç®¡ç†æœ€ä½³å®è·µ

### 1. æ¨¡å—åŒ–è®¾è®¡

```yaml
# åŸºç¡€é…ç½®
defaults:
  - _self_
  - model: base
  - training: base
  - inference: base

# ç‰¹å®šåœºæ™¯é…ç½®
defaults:
  - override /model: fast_inference
```

### 2. å‚æ•°ç»§æ‰¿

```yaml
# çˆ¶é…ç½®ï¼šconfigs/model/base.yaml
model:
  name: "seed_vc"
  version: "v2"
  hidden_size: 768

# å­é…ç½®ï¼šconfigs/model/fast.yaml
name: ${model.name}_fast
hidden_size: 256  # è¦†ç›–çˆ¶é…ç½®
```

### 3. åŠ¨æ€å‚æ•°

```python
# æ ¹æ®è®¾å¤‡åŠ¨æ€è®¾ç½®
device_config = {
    "cuda": {
        "batch_size": 64,
        "gradient_accumulation": 1
    },
    "cpu": {
        "batch_size": 8,
        "gradient_accumulation": 8
    }
}

device_type = "cuda" if torch.cuda.is_available() else "cpu"
config.training.update(device_config[device_type])
```

### 4. ç¯å¢ƒå˜é‡

```yaml
# ä½¿ç”¨ç¯å¢ƒå˜é‡
model:
  name: ${oc.env:MODEL_NAME, "seed_vc"}
  checkpoint_path: ${oc.env:CHECKPOINT_PATH, "checkpoints/model.pt"}
  num_workers: ${oc.env:NUM_WORKERS, 4}
```

---

## ğŸ“Š é…ç½®å¯¹æ¯”

### æ¨¡å‹è§„æ¨¡å¯¹æ¯”

| è§„æ¨¡ | å‚æ•°é‡ | æ¨ç†æ—¶é—´ | å†…å­˜å ç”¨ | è´¨é‡è¯„åˆ† |
|------|--------|----------|----------|----------|
| Tiny | 40M | ~0.3s | 200MB | 3.2/5 |
| Small | 80M | ~0.5s | 400MB | 3.8/5 |
| Base | 150M | ~0.8s | 800MB | 4.2/5 |
| Large | 300M | ~1.2s | 1.5GB | 4.5/5 |

### é‡åŒ–é…ç½®å¯¹æ¯”

| ç»´åº¦ | å‹ç¼©ç‡ | è´¨é‡æŸå¤± | æ¨ç†åŠ é€Ÿ |
|------|--------|----------|----------|
| 32ç»´ | 96x | ~5% | 2.5x |
| 512ç»´ | 6x | ~2% | 1.5x |
| 2048ç»´ | 1.5x | ~1% | 1.2x |

---

*æ­¤æ–‡æ¡£ç”± Claude Code è‡ªåŠ¨ç”Ÿæˆäº 2025-10-28*
